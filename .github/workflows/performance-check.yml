# .github/workflows/performance-check.yml
name: Performance Check
on:
  pull_request:
    types: [opened, synchronize, reopened]
    branches: [main, master]

jobs:
  performance-check:
    runs-on: ubuntu-latest  # Use GitHub runners for consistency
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Needed for baseline comparison
      
      - name: Setup Java
        uses: actions/setup-java@v4
        with:
          distribution: 'temurin'
          java-version: 21
      
      - name: Cache Maven dependencies
        uses: actions/cache@v3
        with:
          path: ~/.m2
          key: ${{ runner.os }}-m2-${{ hashFiles('**/pom.xml') }}
      
      - name: Prepare runner (pin CPU governor)
        if: runner.os == 'Linux'
        run: |
          # Try to set performance governor, but don't fail if not possible
          sudo bash -c 'for c in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor; do echo performance > $c; done' || echo "Could not set CPU governor (expected on GitHub runners)"
      
      - name: Build and install project
        run: ./mvnw -q -B -DskipTests clean install
      
      - name: Run performance comparison
        id: perf-test
        timeout-minutes: 15  # Increased timeout for comprehensive testing (5000 regexps)
        run: |
          echo "Running comprehensive performance comparison with full Wuthering Heights corpus..."
          
          # Create baseline directory
          mkdir -p benchmarks/baseline
          
          # Run the comprehensive performance test using full Wuthering Heights corpus
          MAX_REGEXPS=5000  # Comprehensive scale for robust performance validation
          NUM_RUNS=5        # Increased runs for better statistical significance
          
          ./mvnw -q -B -pl rmatch-tester exec:java \
            -Dexec.mainClass=no.rmz.rmatch.performancetests.GitHubActionPerformanceTestRunner \
            -Dexec.args="${MAX_REGEXPS} ${NUM_RUNS}" \
            || exit 1
      
      - name: Generate performance charts
        run: |
          # Install Python dependencies for chart generation
          python3 -m pip install --user -r requirements.txt
          
          # Generate performance evolution charts
          python3 scripts/generate_performance_charts.py
          
          # Generate macro performance timeline chart
          echo "Generating macro performance timeline chart..."
          python3 scripts/generate_macro_performance_plot.py
      
      - name: Commit updated performance timeline
        if: github.event_name == 'pull_request'
        run: |
          # Configure git
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          
          # Check if performance_timeline.png was updated
          if [ -f "performance_timeline.png" ]; then
            git add performance_timeline.png
            
            # Only commit if there are changes
            if ! git diff --staged --quiet; then
              git commit -m "chore: update macro performance timeline chart
              
              Auto-generated after running performance benchmarks
              
              [skip ci]"
              
              # Push the changes back to the PR branch
              git push origin HEAD:${{ github.head_ref }}
              echo "✅ Updated performance timeline chart committed to PR"
            else
              echo "ℹ️  No changes to performance timeline chart"
            fi
          else
            echo "⚠️  Performance timeline chart not found"
          fi
      
      - name: Compare and comment
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          # Enhanced compare and comment script with pass/fail logic
          ./scripts/compare_and_comment.sh
          exit_code=$?
          
          # Set job status based on performance criteria
          if [ $exit_code -eq 0 ]; then
            echo "Performance check PASSED"
          elif [ $exit_code -eq 1 ]; then
            echo "Performance check FAILED - regression detected"
            exit 1
          elif [ $exit_code -eq 2 ]; then
            echo "Performance check WARNING - within noise threshold"
          else
            echo "Performance check encountered error"
            exit 1
          fi
      
      - name: Upload performance artifacts
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: performance-results
          path: |
            benchmarks/results/*.json
            benchmarks/results/*.log
            benchmarks/results/*.md
            charts/*.png
            performance_timeline.png
          retention-days: 30
